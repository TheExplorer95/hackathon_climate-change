{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Timer():\n",
    "    \"\"\"\n",
    "    A small class to measure time during training.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._start_time = None\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Start a new timer\n",
    "        \"\"\"\n",
    "        self._start_time = time.perf_counter()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"\n",
    "        Stop the timer, and report the elapsed time\n",
    "        \"\"\"\n",
    "        if self._start_time is None:\n",
    "            print(f\"Timer is not running. Use .start() to start it\")\n",
    "            return 0\n",
    "    \n",
    "        elapsed_time = time.perf_counter() - self._start_time\n",
    "        self._start_time = None\n",
    "        \n",
    "        return elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "models = ['GFDL-ESM4','IPSL-CM6A-LR','MPI-ESM1-2-HR']  # models for temp, prec, LAI\n",
    "day_len = 300  # for gen_data_card()\n",
    "\n",
    "MODEL = np.random.choice(np.array(models))\n",
    "temp_ds = np.array(xr.open_mfdataset('data/near_surface_air_temperature/historical/{}/*.nc'.format(MODEL)).tas)\n",
    "prec_ds = np.array(xr.open_mfdataset('data/precipitation_flux/historical/{}/*.nc'.format(MODEL)).pr)\n",
    "\n",
    "def gen_data_card():\n",
    "    while True:\n",
    "        output_month_i = np.random.randint(0+day_len//30, (2014-1850+1)*12)  # y_pred timepoint in int\n",
    "\n",
    "        # month-based metrics\n",
    "        lai = xr.open_mfdataset('data/leaf_area_index/historical/{}/*.nc'.format(MODEL))\n",
    "\n",
    "        # compute day index\n",
    "        try:\n",
    "            endstamp = lai.indexes['time'].to_datetimeindex()[output_month_i]  # cfttimeindex to datetime\n",
    "        except:\n",
    "            endstamp = lai.indexes['time'][output_month_i]\n",
    "        output_day_i = (endstamp - pd.Timestamp('1850-01-01T12')).days  # output is i-th day in int\n",
    "\n",
    "        # continue with month-based metrics\n",
    "        lai = np.array(lai.lai)[output_month_i]\n",
    "        npp_files = glob.glob('data/net_primary_production_on_land/historical/**/*.nc', recursive=True) \n",
    "        npp = xr.open_mfdataset(np.random.choice(np.array(npp_files)))\n",
    "        npp = np.array(npp.npp)[output_month_i]\n",
    "\n",
    "        # day-based metrics\n",
    "        temp = temp_ds[output_day_i-day_len:output_day_i]\n",
    "        prec = prec_ds[output_day_i-day_len:output_day_i]\n",
    "\n",
    "        inputs = np.stack((temp,prec), axis=-1)  # two features\n",
    "        outputs = np.stack((lai,npp), axis=-1)\n",
    "\n",
    "        yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "ds = tf.data.Dataset.from_generator(gen_data_card,output_types = (tf.float32,tf.float32))\n",
    "train_ds = ds.batch(BATCH_SIZE).take(100)\n",
    "\n",
    "val_ds = ds.batch(BATCH_SIZE).take(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[2.3867644e+02 2.3649663e-06]\n",
      "   [2.3943927e+02 2.2958307e-06]\n",
      "   [2.4007401e+02 1.3001983e-06]\n",
      "   ...\n",
      "   [2.3632162e+02 0.0000000e+00]\n",
      "   [2.3684244e+02 2.0750745e-06]\n",
      "   [2.3722217e+02 2.4921312e-06]]\n",
      "\n",
      "  [[2.4997867e+02 0.0000000e+00]\n",
      "   [2.4988678e+02 0.0000000e+00]\n",
      "   [2.5026993e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4791400e+02 0.0000000e+00]\n",
      "   [2.4865665e+02 0.0000000e+00]\n",
      "   [2.4922894e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.6843695e+02 4.7932292e-05]\n",
      "   [2.7041687e+02 5.4295335e-05]\n",
      "   [2.6982816e+02 9.3458366e-05]\n",
      "   ...\n",
      "   [2.5985541e+02 3.9080294e-07]\n",
      "   [2.5722461e+02 6.8657118e-07]\n",
      "   [2.6226096e+02 7.1367213e-06]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.4889444e+02 0.0000000e+00]\n",
      "   [2.4881516e+02 0.0000000e+00]\n",
      "   [2.4889247e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4671407e+02 0.0000000e+00]\n",
      "   [2.4815601e+02 0.0000000e+00]\n",
      "   [2.4851987e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.4597534e+02 0.0000000e+00]\n",
      "   [2.4625250e+02 0.0000000e+00]\n",
      "   [2.4643192e+02 1.3536102e-06]\n",
      "   ...\n",
      "   [2.4510458e+02 0.0000000e+00]\n",
      "   [2.4520667e+02 0.0000000e+00]\n",
      "   [2.4560881e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.4658041e+02 0.0000000e+00]\n",
      "   [2.4712732e+02 0.0000000e+00]\n",
      "   [2.4750221e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4515671e+02 0.0000000e+00]\n",
      "   [2.4554825e+02 0.0000000e+00]\n",
      "   [2.4595285e+02 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[2.3690781e+02 0.0000000e+00]\n",
      "   [2.3722592e+02 0.0000000e+00]\n",
      "   [2.3816473e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.3478470e+02 0.0000000e+00]\n",
      "   [2.3529680e+02 0.0000000e+00]\n",
      "   [2.3599947e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.5229626e+02 0.0000000e+00]\n",
      "   [2.5280872e+02 0.0000000e+00]\n",
      "   [2.5336952e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4744052e+02 0.0000000e+00]\n",
      "   [2.4905637e+02 0.0000000e+00]\n",
      "   [2.5078133e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.5948962e+02 5.2673545e-06]\n",
      "   [2.6182611e+02 5.8372293e-06]\n",
      "   [2.6436374e+02 3.9900042e-06]\n",
      "   ...\n",
      "   [2.5558752e+02 0.0000000e+00]\n",
      "   [2.5198994e+02 0.0000000e+00]\n",
      "   [2.5589645e+02 5.9467641e-07]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.4553886e+02 0.0000000e+00]\n",
      "   [2.4608656e+02 1.2493272e-06]\n",
      "   [2.4595732e+02 1.6026761e-06]\n",
      "   ...\n",
      "   [2.4365578e+02 0.0000000e+00]\n",
      "   [2.4540097e+02 0.0000000e+00]\n",
      "   [2.4542621e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.4644960e+02 0.0000000e+00]\n",
      "   [2.4588779e+02 0.0000000e+00]\n",
      "   [2.4547939e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4264018e+02 0.0000000e+00]\n",
      "   [2.4348590e+02 0.0000000e+00]\n",
      "   [2.4579620e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.4392856e+02 0.0000000e+00]\n",
      "   [2.4428442e+02 0.0000000e+00]\n",
      "   [2.4435443e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4215460e+02 0.0000000e+00]\n",
      "   [2.4254268e+02 0.0000000e+00]\n",
      "   [2.4325793e+02 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[2.3593535e+02 0.0000000e+00]\n",
      "   [2.3688412e+02 2.5532088e-06]\n",
      "   [2.3863153e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.3347424e+02 0.0000000e+00]\n",
      "   [2.3411325e+02 0.0000000e+00]\n",
      "   [2.3487219e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.4895534e+02 0.0000000e+00]\n",
      "   [2.4886078e+02 0.0000000e+00]\n",
      "   [2.4922729e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4605078e+02 0.0000000e+00]\n",
      "   [2.4653026e+02 0.0000000e+00]\n",
      "   [2.4807253e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.5969833e+02 6.5442036e-06]\n",
      "   [2.6113046e+02 5.4901138e-06]\n",
      "   [2.6324426e+02 3.2140770e-06]\n",
      "   ...\n",
      "   [2.5833878e+02 7.6798487e-06]\n",
      "   [2.5163516e+02 3.3766122e-07]\n",
      "   [2.5505725e+02 2.0805378e-06]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.4277052e+02 0.0000000e+00]\n",
      "   [2.4383313e+02 0.0000000e+00]\n",
      "   [2.4389278e+02 2.9627478e-07]\n",
      "   ...\n",
      "   [2.4559029e+02 0.0000000e+00]\n",
      "   [2.4389157e+02 0.0000000e+00]\n",
      "   [2.4218594e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.4407260e+02 0.0000000e+00]\n",
      "   [2.4297511e+02 1.3912684e-06]\n",
      "   [2.4200056e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4267062e+02 0.0000000e+00]\n",
      "   [2.4355757e+02 0.0000000e+00]\n",
      "   [2.4436424e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.4310577e+02 1.6330093e-06]\n",
      "   [2.4316211e+02 0.0000000e+00]\n",
      "   [2.4374884e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4290041e+02 0.0000000e+00]\n",
      "   [2.4287183e+02 0.0000000e+00]\n",
      "   [2.4291650e+02 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[2.4495555e+02 0.0000000e+00]\n",
      "   [2.4562576e+02 0.0000000e+00]\n",
      "   [2.4615688e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4336320e+02 0.0000000e+00]\n",
      "   [2.4390514e+02 0.0000000e+00]\n",
      "   [2.4449939e+02 3.0943886e-07]]\n",
      "\n",
      "  [[2.6413803e+02 0.0000000e+00]\n",
      "   [2.6366739e+02 0.0000000e+00]\n",
      "   [2.6343378e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.6203531e+02 0.0000000e+00]\n",
      "   [2.6380865e+02 3.2628975e-07]\n",
      "   [2.6428592e+02 3.4585486e-07]]\n",
      "\n",
      "  [[2.6886356e+02 4.9959167e-06]\n",
      "   [2.6997559e+02 2.8934089e-06]\n",
      "   [2.7068347e+02 8.3147170e-06]\n",
      "   ...\n",
      "   [2.6936737e+02 0.0000000e+00]\n",
      "   [2.6860419e+02 0.0000000e+00]\n",
      "   [2.6835181e+02 0.0000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.4700504e+02 1.8462597e-06]\n",
      "   [2.4858987e+02 1.2175374e-05]\n",
      "   [2.4973637e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4951201e+02 1.4785703e-06]\n",
      "   [2.4848840e+02 7.1591370e-07]\n",
      "   [2.4847028e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.5014894e+02 1.4852673e-06]\n",
      "   [2.5043314e+02 1.7370444e-06]\n",
      "   [2.5092580e+02 2.4395158e-06]\n",
      "   ...\n",
      "   [2.4979926e+02 0.0000000e+00]\n",
      "   [2.4987009e+02 8.9024149e-07]\n",
      "   [2.4997221e+02 1.4228299e-06]]\n",
      "\n",
      "  [[2.4988124e+02 0.0000000e+00]\n",
      "   [2.4978145e+02 0.0000000e+00]\n",
      "   [2.4953889e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.5040669e+02 0.0000000e+00]\n",
      "   [2.5026491e+02 0.0000000e+00]\n",
      "   [2.5002579e+02 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[2.4622552e+02 0.0000000e+00]\n",
      "   [2.4680215e+02 0.0000000e+00]\n",
      "   [2.4738419e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4494000e+02 0.0000000e+00]\n",
      "   [2.4533478e+02 0.0000000e+00]\n",
      "   [2.4570142e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.6385742e+02 0.0000000e+00]\n",
      "   [2.6326776e+02 0.0000000e+00]\n",
      "   [2.6287015e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.6165552e+02 0.0000000e+00]\n",
      "   [2.6352823e+02 0.0000000e+00]\n",
      "   [2.6403979e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.6990118e+02 1.8002586e-06]\n",
      "   [2.7023581e+02 4.4560657e-06]\n",
      "   [2.7046033e+02 7.1917880e-06]\n",
      "   ...\n",
      "   [2.6845392e+02 0.0000000e+00]\n",
      "   [2.6764514e+02 0.0000000e+00]\n",
      "   [2.6885040e+02 0.0000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.4597978e+02 1.3828799e-06]\n",
      "   [2.4795929e+02 4.8887309e-06]\n",
      "   [2.5019322e+02 1.1433801e-06]\n",
      "   ...\n",
      "   [2.5039432e+02 0.0000000e+00]\n",
      "   [2.4901883e+02 0.0000000e+00]\n",
      "   [2.4675552e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.4913531e+02 2.7435692e-06]\n",
      "   [2.4945683e+02 0.0000000e+00]\n",
      "   [2.5008551e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.5090213e+02 2.6472828e-06]\n",
      "   [2.4970399e+02 0.0000000e+00]\n",
      "   [2.4870013e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.4959827e+02 0.0000000e+00]\n",
      "   [2.4956003e+02 0.0000000e+00]\n",
      "   [2.4946002e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4975766e+02 0.0000000e+00]\n",
      "   [2.4973248e+02 0.0000000e+00]\n",
      "   [2.4965837e+02 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[2.4578654e+02 0.0000000e+00]\n",
      "   [2.4689066e+02 0.0000000e+00]\n",
      "   [2.4762668e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4452194e+02 0.0000000e+00]\n",
      "   [2.4488812e+02 0.0000000e+00]\n",
      "   [2.4495026e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.6334494e+02 0.0000000e+00]\n",
      "   [2.6273077e+02 0.0000000e+00]\n",
      "   [2.6222095e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.6110269e+02 0.0000000e+00]\n",
      "   [2.6316501e+02 0.0000000e+00]\n",
      "   [2.6364648e+02 0.0000000e+00]]\n",
      "\n",
      "  [[2.7065555e+02 0.0000000e+00]\n",
      "   [2.7075879e+02 1.4660218e-05]\n",
      "   [2.7071918e+02 1.6925162e-06]\n",
      "   ...\n",
      "   [2.6876297e+02 0.0000000e+00]\n",
      "   [2.6773404e+02 0.0000000e+00]\n",
      "   [2.6926440e+02 9.1144011e-07]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.5451242e+02 1.9964968e-05]\n",
      "   [2.5520346e+02 1.5372832e-05]\n",
      "   [2.5587115e+02 1.0776964e-05]\n",
      "   ...\n",
      "   [2.5046970e+02 1.2915272e-05]\n",
      "   [2.5172162e+02 1.7470140e-05]\n",
      "   [2.5365919e+02 1.9670810e-05]]\n",
      "\n",
      "  [[2.5129663e+02 5.7082639e-06]\n",
      "   [2.5175125e+02 5.8205837e-06]\n",
      "   [2.5205429e+02 8.6602413e-06]\n",
      "   ...\n",
      "   [2.5016269e+02 1.5318969e-06]\n",
      "   [2.5041896e+02 3.2153052e-06]\n",
      "   [2.5072684e+02 4.1614867e-06]]\n",
      "\n",
      "  [[2.4909378e+02 0.0000000e+00]\n",
      "   [2.4875304e+02 0.0000000e+00]\n",
      "   [2.4832906e+02 0.0000000e+00]\n",
      "   ...\n",
      "   [2.4976149e+02 0.0000000e+00]\n",
      "   [2.4959453e+02 0.0000000e+00]\n",
      "   [2.4933945e+02 0.0000000e+00]]]], shape=(300, 36, 72, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for i in train_ds.take(1):\n",
    "    print(i[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(tf.keras.Model):\n",
    "    def __init__(self, num_filters):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.convlstm2D_1 = tf.keras.layers.ConvLSTM2D(filters = num_filters, kernel_size=(3,3),\n",
    "                                                     padding=\"same\",return_sequences=True)\n",
    "        \n",
    "        \n",
    "        self.bn_1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.convlstm2D_2 = tf.keras.layers.ConvLSTM2D(filters = num_filters, kernel_size=(3,3),\n",
    "                                                     padding=\"same\",return_sequences=True)\n",
    "\n",
    "        self.bn_2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "\n",
    "        self.convlstm2D_3 = tf.keras.layers.ConvLSTM2D(filters = num_filters, kernel_size=(3,3),\n",
    "                                                     padding=\"same\",return_sequences=True)\n",
    "\n",
    "        self.bn_3 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.convlstm2D_4 = tf.keras.layers.ConvLSTM2D(filters = num_filters, kernel_size=(3,3),\n",
    "                                                     padding=\"same\",return_sequences=True)\n",
    "\n",
    "        self.bn_4 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv3d = tf.keras.layers.Conv3D(filters = 2, kernel_size = (3,3,3), \n",
    "                                             activation= \"relu\", padding=\"same\")\n",
    "        \n",
    "        \n",
    "\n",
    "    def call(self,x,training):\n",
    "        \n",
    "        x = self.convlstm2D_1(x,training= training)\n",
    "        x = self.bn_1(x,training = training)\n",
    "        x = self.convlstm2D_2(x,training = training)\n",
    "        x = self.bn_2(x,training = training)\n",
    "        x = self.convlstm2D_3(x,training = training)\n",
    "        x = self.bn_3(x,training = training)\n",
    "        x = self.convlstm2D_4(x,training = training)\n",
    "        x = self.bn_4(x, training = training)\n",
    "        x = self.conv3d(x)\n",
    "        \n",
    "        # bottleneck (change time_step dim to be channel dimension so we can use the bottleneck)\n",
    "        #x = tf.transpose(x, [0,4,2,3,1])\n",
    "        #x = self.bottleneck(x)\n",
    "        # change back to desired dimensions\n",
    "        #x = tf.transpose(x, [0,4,2,3,1])\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(model, data, loss_function, optimizer, train_loss_metric, train_acc_metric):\n",
    "    '''\n",
    "    Training for one epoch.\n",
    "    '''\n",
    "    for img, target in train_ds:\n",
    "        # forward pass with GradientTape\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = model(img, training=True)\n",
    "            loss = loss_function(target, prediction) + tf.reduce_sum(model.losses)\n",
    "\n",
    "        # backward pass via GradienTape (auto-gradient calc)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # update metrics\n",
    "        train_loss_metric.update_state(loss)\n",
    "        train_acc_metric.update_state(target, prediction)\n",
    "        \n",
    "        \n",
    "def eval_step(model, ds, loss_function, loss_metric, acc_metric):\n",
    "    '''\n",
    "    Evaluation Loop.\n",
    "    '''\n",
    "    for sequence, target in ds:\n",
    "        # forward pass\n",
    "        prediction = model(sequence, training=False)\n",
    "        # update metrics\n",
    "        loss = loss_function(target, prediction)\n",
    "        loss_metric.update_state(loss)\n",
    "        acc_metric.update_state(target, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_lstm_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_4 (ConvLSTM2D)  multiple                  1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch multiple                  20        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_5 (ConvLSTM2D)  multiple                  1820      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch multiple                  20        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_6 (ConvLSTM2D)  multiple                  1820      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch multiple                  20        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_7 (ConvLSTM2D)  multiple                  1820      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch multiple                  20        \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            multiple                  272       \n",
      "=================================================================\n",
      "Total params: 7,092\n",
      "Trainable params: 7,052\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "months = 10\n",
    "\n",
    "#Shape: None(unspecified) batches, timesteps(in days), 72 (latitudes), 36 (longitudes), 2(temperature&precipitation)\n",
    "input_shape = (16, months*30.5, 72, 36, 2)\n",
    "\n",
    "model = ConvLSTM(num_filters=5)\n",
    "\n",
    "model.build((16,120,72,36,2))\n",
    "model.summary() # shows number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 0.0003\n",
    "model = ConvLSTM(num_filters = 10)\n",
    "loss_function = tf.keras.losses.MSE\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate) \n",
    "\n",
    "timer = Timer()\n",
    "\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy('train_accuracy')\n",
    "val_acc_metric = tf.keras.metrics.CategoricalAccuracy('val_accuracy')\n",
    "\n",
    "train_loss_metric = tf.keras.metrics.Mean('train_loss')\n",
    "val_loss_metric = tf.keras.metrics.Mean('val_loss')\n",
    "\n",
    "# initialize the logger for Tensorboard visualization\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train_ConvLSTM'    \n",
    "val_log_dir = 'logs/gradient_tape/' + current_time + '/val_ConvLSTM'       \n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)  \n",
    "val_summary_writer = tf.summary.create_file_writer(val_log_dir)\n",
    "\n",
    "\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH] ____________________0____________________\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,36,72,10] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Minimum]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-e118749df0be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Evaluating training metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-36fd9db54a55>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, data, loss_function, optimizer, train_loss_metric, train_acc_metric)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# forward pass with GradientTape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-501f8e5ae037>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvlstm2D_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvlstm2D_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional_recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    871\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_reset_cell_dropout_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m     return super(ConvLSTM2D, self).call(inputs,\n\u001b[0m\u001b[1;32m    874\u001b[0m                                         \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                                         \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional_recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     last_output, outputs, states = K.rnn(step,\n\u001b[0m\u001b[1;32m    326\u001b[0m                                          \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                                          \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4236\u001b[0;31m       final_outputs = control_flow_ops.while_loop(\n\u001b[0m\u001b[1;32m   4237\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4238\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   4220\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4221\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4222\u001b[0;31m         output, new_states = step_function(current_input,\n\u001b[0m\u001b[1;32m   4223\u001b[0m                                            tuple(states) + tuple(constants))\n\u001b[1;32m   4224\u001b[0m         \u001b[0mflat_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional_recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     last_output, outputs, states = K.rnn(step,\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional_recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_f\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_tm1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_c\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_o\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/activations.py\u001b[0m in \u001b[0;36mhard_sigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;36m0.2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.5\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m   \"\"\"\n\u001b[0;32m--> 335\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhard_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mhard_sigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   4732\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_two\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4733\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_five\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4734\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4735\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/ops/clip_ops.py\u001b[0m in \u001b[0;36mclip_by_value\u001b[0;34m(t, clip_value_min, clip_value_max, name)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Go through list of tensors, for each value in each tensor clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mt_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_value_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Assert that the shape is compatible with the initial shape,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# to prevent unintentional broadcasting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mminimum\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   5959\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5960\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5961\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5962\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5963\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_2/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,36,72,10] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Minimum]"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'\\n[EPOCH] ____________________{epoch}____________________')\n",
    "    \n",
    "    # training step with metrics update--------------------------------------------------------\n",
    "    timer.start()\n",
    "\n",
    "    train_step(model, train_ds, loss_function, optimizer, train_loss_metric, train_acc_metric)\n",
    "\n",
    "    # Evaluating training metrics\n",
    "    train_loss = train_loss_metric.result()\n",
    "    train_acc = train_acc_metric.result()\n",
    "    \n",
    "    with train_summary_writer.as_default():     # logging our metrics to a file which is used by tensorboard\n",
    "        tf.summary.scalar('loss', train_loss, step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_acc, step=epoch)\n",
    "\n",
    "    \n",
    "    elapsed_time = timer.stop()\n",
    "    \n",
    "    print(f'[{epoch}] - Finished Epoch in {elapsed_time:0.2f} seconds - train_loss: {train_loss:0.4f}, train_acc: {train_acc:0.4f}')\n",
    "    \n",
    "    # evaluation step with metrics update--------------------------------------------------------\n",
    "    timer.start()\n",
    "\n",
    "    eval_step(model, val_ds, loss_function, \n",
    "              loss_metric=val_loss_metric, \n",
    "              acc_metric=val_acc_metric)\n",
    "\n",
    "    # Evaluating validation metrics\n",
    "    val_loss = val_loss_metric.result()\n",
    "    val_acc = val_acc_metric.result()\n",
    "    \n",
    "    with val_summary_writer.as_default():       # logging our metrics to a file which is used by tensorboard\n",
    "        tf.summary.scalar('loss', val_loss, step=epoch)\n",
    "        tf.summary.scalar('accuracy', val_acc, step=epoch)\n",
    "    \n",
    "    #print(f'\\n[{epoch}] - Finished evaluation - val_loss: {val_loss:0.4f}, val_accuracy: {val_acc:0.4f}')\n",
    "    \n",
    "    # Resetting train and validation metrics-----------------------------------------------------\n",
    "    train_acc_metric.reset_states()\n",
    "    val_acc_metric.reset_states()\n",
    "    train_loss_metric.reset_states()\n",
    "    val_loss_metric.reset_states()\n",
    "    \n",
    "    elapsed_time = timer.stop()\n",
    "    times.append(elapsed_time)\n",
    "  \n",
    "    if epoch%3 == 0:\n",
    "        print(f'\\n[INFO] - Total time elapsed: {np.sum(times)/60:0.4f} min. Total time remaining: {(np.sum(times)/(epoch+1))*(epochs-epoch-1)/60:0.4f} min.')\n",
    "\n",
    "print(f'[INFO] - Total run time: {np.sum(times)/60:0.4f} min.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
