{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict single timeslice\n",
    "\n",
    "- Given $t_{-n}, ..., t_{-1}$ inputs, predict outputs at $t_{-1}$\n",
    "- Give two features as an extra dimension\n",
    "- Given an output month, use fixed length of days input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_models = ['GFDL-ESM4','IPSL-CM6A-LR','MPI-ESM1-2-HR']  # models for temp, prec, LAI\n",
    "day_len = 300  # for gen_data_card()\n",
    "batch_size = 32\n",
    "# num_cores = 8\n",
    "\n",
    "# choose a model\n",
    "dmodel = np.random.choice(np.array(data_models)) \n",
    "# load all data externally to save computationtime\n",
    "temp_ds = np.array(xr.open_mfdataset('data/near_surface_air_temperature/historical/{}/*.nc'.format(dmodel)).tas)\n",
    "prec_ds = np.array(xr.open_mfdataset('data/precipitation_flux/historical/{}/*.nc'.format(dmodel)).pr)\n",
    "npp_files = glob.glob('data/net_primary_production_on_land/historical/**/*.nc', recursive=True) \n",
    "npp_ds = np.array(xr.open_mfdataset(np.random.choice(np.array(npp_files))).npp)\n",
    "lai_ds = xr.open_mfdataset('data/leaf_area_index/historical/{}/*.nc'.format(dmodel))\n",
    "\n",
    "# define range for month index\n",
    "max_month = 1978\n",
    "min_month = day_len//28\n",
    "\n",
    "\n",
    "def gen_data_card():\n",
    "    while True:\n",
    "        # array to append to\n",
    "        endstamp = []\n",
    "        output_day_i = np.zeros(batch_size)\n",
    "        lai = np.zeros((batch_size, npp_ds.shape[1], npp_ds.shape[2]))  # batch, lat, lon\n",
    "        npp = np.zeros((batch_size, npp_ds.shape[1], npp_ds.shape[2]))\n",
    "        temp = np.zeros((batch_size, day_len, npp_ds.shape[1], npp_ds.shape[2]))  # batch, time, lat, lon\n",
    "        prec = np.zeros((batch_size, day_len, npp_ds.shape[1], npp_ds.shape[2]))\n",
    "        \n",
    "        # index of output in month\n",
    "        output_month_i = np.random.randint(min_month, max_month, size=batch_size)  # y_pred timepoint in int\n",
    "\n",
    "        # convert output index to timestamp\n",
    "        try:\n",
    "            for i in range(batch_size):\n",
    "                endstamp.append(lai_ds.indexes['time'].to_datetimeindex()[output_month_i[i]])  # cfttimeindex to datetime               \n",
    "        except:\n",
    "            for i in range(batch_size):\n",
    "                endstamp.append(lai_ds.indexes['time'][output_month_i[i]])\n",
    "\n",
    "        # convert output month index to day index\n",
    "        for i in range(batch_size):\n",
    "            output_day_i[i] = (endstamp[i] - pd.Timestamp('1850-01-01T12')).days  # output is i-th day in int\n",
    "        output_day_i = np.int_(output_day_i)\n",
    "#         # use joblib parrallelization, but somehow slower?\n",
    "#         my_f = lambda x: (x - pd.Timestamp('1850-01-01T12')).days\n",
    "#         sub_ary = joblib.Parallel(n_jobs=num_cores)(              \n",
    "#                       delayed(my_f)(endstamp[i])\n",
    "#                       for i in range(batch_size)) \n",
    "#         output_day_i = np.int_(np.stack(sub_ary, axis=0))\n",
    "\n",
    "        # save month-based time slices\n",
    "        lainp = np.array(lai_ds.lai)\n",
    "        for i in range(batch_size):\n",
    "            lai[i] = lainp[output_month_i[i]]\n",
    "        for i in range(batch_size):\n",
    "            npp[i] = npp_ds[output_month_i[i]]\n",
    "\n",
    "        # day-based metrics\n",
    "        for i in range(batch_size):\n",
    "            temp[i] = temp_ds[output_day_i[i]-day_len:output_day_i[i]]\n",
    "        for i in range(batch_size):\n",
    "            prec[i] = prec_ds[output_day_i[i]-day_len:output_day_i[i]]\n",
    "\n",
    "        # merge features\n",
    "        inputs = np.stack((temp,prec), axis=-1)  # two features\n",
    "        outputs = np.stack((lai,npp), axis=-1)\n",
    "        outputs = np.nan_to_num(outputs)\n",
    "\n",
    "        yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.6816175480000197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 300, 36, 72, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mygen = gen_data_card()\n",
    "a = next(mygen)\n",
    "a[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
