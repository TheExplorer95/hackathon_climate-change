{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: solve differenct calendar mismatch\n",
    "# https://climate-cms.org/2019/11/12/Calendars-and-monthly-data.html\n",
    "\n",
    "batch_size = 32\n",
    "time_len = 10  # how long each training sample should be, in months\n",
    "models = ['GFDL-ESM4','IPSL-CM6A-LR','MPI-ESM1-2-HR']  # models for temp, prec, LAI\n",
    "\n",
    "def gen_data_card():  \n",
    "    model = np.random.choice(np.array(models))  # which of 3 models to choose from\n",
    "    \n",
    "    # MONTHLY PICK\n",
    "    start_year = np.random.randint(1850,2014+1) # randomly select a start year of a time slice\n",
    "    start_month = np.random.randint(1,12+1)\n",
    "    end_year = start_year + ((start_month+time_len-1) // 12)\n",
    "    end_month = (start_month+time_len) % 12\n",
    "    if end_month == 0:\n",
    "        end_month = 12\n",
    "    month_index_start = (start_year-1850)*12 + start_month  # convert date into index with 01-1850 as 0\n",
    "    month_index_end = month_index_start + time_len\n",
    "    print(\"index:\", month_index_start, month_index_end)\n",
    "    print(model,start_year, start_month, end_year, end_month)\n",
    "    \n",
    "    # select appropriate time slices\n",
    "    temp = xr.open_mfdataset('data/near_surface_air_temperature/historical/{}/*.nc'.format(model))\n",
    "    temp = temp.tas.loc[\"{}-{}-16\".format(start_year, start_month):\"{}-{}-16\".format(end_year, end_month)]  \n",
    "    \n",
    "    prec = xr.open_mfdataset('data/precipitation_flux/historical/{}/*.nc'.format(model))\n",
    "    prec = prec.pr.loc[\"{}-{}-16\".format(start_year, start_month):\"{}-{}-16\".format(end_year, end_month)]  \n",
    "    \n",
    "    lai = xr.open_mfdataset('data/leaf_area_index/historical/{}/*.nc'.format(model))\n",
    "    lai = np.array(lai.lai)[month_index_start:month_index_end]\n",
    "          \n",
    "    # TODO: currently select randomly, but averaging or using only one is also an option\n",
    "    npp_files = glob.glob('data/net_primary_production_on_land/historical/**/*.nc', recursive=True) \n",
    "    npp = xr.open_mfdataset(np.random.choice(np.array(npp_files)))\n",
    "    npp = np.array(npp.npp)[month_index_start:month_index_end]\n",
    "                \n",
    "    # concatanate data\n",
    "    inputs = np.array(xr.concat((temp,prec), dim='lat'))  # two maps next to each other\n",
    "    outputs = np.concatenate((lai,npp), axis=1)\n",
    "    \n",
    "    yield(inputs, outputs)\n",
    "    \n",
    "    \n",
    "    ### snippets to convert cftime.NoLeap to pandas.datetime\n",
    "    #     try:  # for GFDL, index are in cftime.timenoleap\n",
    "    #         datetimeindex = lai.indexes['time'].to_datetimeindex()\n",
    "    #         lai['time'] = datetimeindex  \n",
    "    #     except:  # else in pandas datetime index\n",
    "    #         pass\n",
    "    \n",
    "    ### snippets to handle different sampling date for februrary\n",
    "     #     try:  # TODO: feburary is 15th, try-catch still doesn't work sometimes?\n",
    "    #         npp = npp.npp.loc[\"{}-{}-16\".format(start_year, start_month):\"{}-{}-16\".format(end_year, end_month)]\n",
    "    #         print(\"16,16\")\n",
    "    #     except ValueError:\n",
    "    #         try:\n",
    "    #             npp = npp.npp.loc[\"{}-{}-16\".format(start_year, start_month):\"{}-{}-15\".format(end_year, end_month)]\n",
    "    #             print('16,15')\n",
    "    #         except ValueError:\n",
    "    #             try:\n",
    "    #                 npp = npp.npp.loc[\"{}-{}-15\".format(start_year, start_month):\"{}-{}-16\".format(end_year, end_month)]\n",
    "    #                 print('15,16')\n",
    "    #             except ValueError:\n",
    "    #                 npp = npp.npp.loc[\"{}-{}-15\".format(start_year, start_month):\"{}-{}-15\".format(end_year, end_month)]\n",
    "    #                 print('15,15')\n",
    "    \n",
    "    \n",
    "    # DAILY PICK\n",
    "#     start_time = np.random.choice(np.arange(0, (2014-1850+1)*365-time_slice, ))\n",
    "#     start_time = np.random.randint(0, (2014-1850+1)*365-time_slice)  # choose a random slice start point\n",
    "# #     file_i_start = (start_time-365) // (365*10)  # figure out which file should be opened\n",
    "# #     file_i_end = (start_time+time_len-365) // (365*10)  # eventually, two or multiple should be opened\n",
    "#     temp = xr.open_mfdataset('data/near_surface_air_temperature/historical/{}/*.nc'.format(model))  # load all in one xarray\n",
    "#     temp = temp.tas[start_time : start_time+time_len]  # select the right slice\n",
    "#     prec = xr.open_mfdataset('data/precipitation_flux/historical/{}/*.nc'.format(model))\n",
    "#     prec = prec.pr[start_time : start_time+time_len]\n",
    "#     lai = xr.open_mfdataset('data/leaf_area_index/historical/{}/*.nc'.format(model))\n",
    "#     lai = lai.lai[start_time//31 : ]  # TODO: daily slice and monthly slice don't match (17.03-25.04 /= 01.03-01.05)\n",
    "    \n",
    "    # LOAD SEPARATE DATA\n",
    "#     files = sorted(glob.glob('./data/near_surface_air_temperature/historical/{}/*'.format(model)))  # all files in dir\n",
    "#     years_i = np.random.randint(0, len(files))  # which years data should be used?\n",
    "#     temp = xr.open_dataset(files[years_i]).tas  # choose a random dataset\n",
    "#     day = np.random.randint(0, temp.shape[0]-time_len)  # choose a day where slice start # TODO: doesn't work with 1850\n",
    "#     temp = temp[day:day+time_len]  # select a slice\n",
    "    \n",
    "#     # precipitation\n",
    "#     files = glob.glob('./data/precipitation_flux/historical/{}/*'.format(model))  # all files in dir\n",
    "#     temp = xr.open_dataset(np.random.choice(files)).tas  # choose a random dataset\n",
    "#     day = np.random.randint(0, temp.shape[0]-time_slice)  # choose a day where slice start # TODO: doesn't work with 1850\n",
    "#     temp = temp[day:day+time_slice]  # select a slice\n",
    "\n",
    "# #     lai = \n",
    "# #     npp = \n",
    "#     inputs = xr.concat((temp,prec), dim='lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 27 37\n",
      "MPI-ESM1-2-HR 1852 3 1853 1\n"
     ]
    }
   ],
   "source": [
    "data_gen = gen_data_card()\n",
    "din, dout = next(data_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
