{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data param\n",
    "day_len = 40\n",
    "total_months = (2100-2015+1)*12\n",
    "batch_size = total_months  # predict all points at once\n",
    "\n",
    "# model param\n",
    "num_filters = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_models = ['GFDL-ESM4','IPSL-CM6A-LR','MPI-ESM1-2-HR']  # models for temp, prec, LAI\n",
    "dmodel = 'IPSL-CM6A-LR' # np.random.choice(np.array(data_models))  # TODO: choose a model\n",
    "scenarios = ['ssp126', 'ssp370', 'ssp585']\n",
    "scenario = scenarios[0]\n",
    "\n",
    "# load historical data\n",
    "dx_temp = xr.open_mfdataset('data/near_surface_air_temperature/historical/{}/*.nc'.format(dmodel)).tas\n",
    "dx_prec = xr.open_mfdataset('data/precipitation_flux/historical/{}/*.nc'.format(dmodel)).pr\n",
    "\n",
    "# load prediction of climate until 2100 and concatanate with historical data\n",
    "dx_temp_future = xr.open_mfdataset('data/near_surface_air_temperature/{}/{}/*.nc'.format(scenario, dmodel)).tas\n",
    "dx_temp_future = xr.concat((dx_temp, dx_temp_future), dim='time')\n",
    "dx_prec_future = xr.open_mfdataset('data/precipitation_flux/{}/{}/*.nc'.format(scenario, dmodel)).pr\n",
    "dx_prec_future = xr.concat((dx_prec, dx_prec_future), dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "one could also use just function. Systematically sliding window to predict all future months using timestamp index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_future_climate():\n",
    "#     first_month = (2015-1850)*12 + 1  # int index of which month january 2015 is with 0 being january 1850\n",
    "    counter = 0\n",
    "    while counter < total_months: # predict from 2015 to 2100\n",
    "        cyear = (counter+1) // 12 + 2015\n",
    "        cmonth = (counter+1) % 12\n",
    "        if cmonth == 0:\n",
    "            cmonth = 12\n",
    "        current_timestamp = pd.Timestamp(cyear, cmonth, 1)\n",
    "        input_start_timestamp = current_timestamp - pd.Timedelta(day_len-1, unit='day')\n",
    "        \n",
    "        counter += 1\n",
    "        yield (np.stack((np.array(dx_temp_future.loc[input_start_timestamp:current_timestamp+pd.Timedelta(1,unit='day')]),\n",
    "                         np.array(dx_prec_future.loc[input_start_timestamp:current_timestamp+pd.Timedelta(1,unit='day')])),\n",
    "                         axis=-1)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pipeline\n",
    "ds_future = tf.data.Dataset.from_generator(generator=gen_future_climate, output_types=(tf.float32)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(tf.keras.Model):\n",
    "    def __init__(self, num_filters):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self.convlstm2D_1 = tf.keras.layers.ConvLSTM2D(filters = num_filters, kernel_size=(3,3),\n",
    "                                                     padding=\"same\", return_sequences=True,\n",
    "                                                      activation = \"tanh\")\n",
    "        self.bn_1 = tf.keras.layers.BatchNormalization()\n",
    "        #self.acti_1 = tf.keras.layers.Activation(activation)\n",
    "        \n",
    "        self.convlstm2D_2 = tf.keras.layers.ConvLSTM2D(filters = num_filters, kernel_size=(3,3),\n",
    "                                                     padding=\"same\", return_sequences=True,\n",
    "                                                      activation = \"tanh\")\n",
    "        self.bn_2 = tf.keras.layers.BatchNormalization()\n",
    "        #self.acti_2 = tf.keras.layers.Activation(activation)\n",
    "\n",
    "\n",
    "        self.convlstm2D_3 = tf.keras.layers.ConvLSTM2D(filters = num_filters, kernel_size=(3,3),\n",
    "                                                     padding=\"same\", return_sequences=True,\n",
    "                                                      activation = \"tanh\")\n",
    "        self.bn_3 = tf.keras.layers.BatchNormalization()\n",
    "        #self.acti_3 = tf.keras.layers.Activation(activation)\n",
    "        \n",
    "        self.convlstm2D_4 = tf.keras.layers.ConvLSTM2D(filters = num_filters, kernel_size=(3,3),\n",
    "                                                     padding=\"same\", return_sequences=True,\n",
    "                                                      activation = \"tanh\")\n",
    "        self.bn_4 = tf.keras.layers.BatchNormalization()\n",
    "        #self.acti_4 = tf.keras.layers.Activation(activation)\n",
    "        \n",
    "        # convolve over time, lat, lon. This means that we assume timesteps close to each other share local similarities\n",
    "        self.conv3d = tf.keras.layers.Conv3D(filters = 2, kernel_size = (3,3,3), \n",
    "                                             activation= \"tanh\", padding=\"same\")\n",
    "        # computed convolved sum over all time dimension to get a single time slice\n",
    "        self.bottleneck = tf.keras.layers.Conv3D(filters=1, kernel_size=1, activation=\"relu\",strides=1)\n",
    "\n",
    "\n",
    "    def call(self, x, training, input_shape):\n",
    "        # (batch, time, lat, lon, channel)\n",
    "        x = tf.ensure_shape(x, input_shape) \n",
    "        # (batch, time, lat, lon, channel)\n",
    "        x = self.convlstm2D_1(x,training= training)\n",
    "        # (batch, time, lat1, lon1, filter1)\n",
    "        x = self.bn_1(x,training = training)\n",
    "        \n",
    "        x = self.convlstm2D_2(x,training = training)\n",
    "        x = self.bn_2(x,training = training)\n",
    "        \n",
    "        x = self.convlstm2D_3(x,training = training)\n",
    "        x = self.bn_3(x,training = training)\n",
    "        \n",
    "        x = self.convlstm2D_4(x,training = training)\n",
    "        x = self.bn_4(x, training = training)\n",
    "        # (batch, time, lat4, lon4, filter4)\n",
    "        x = self.conv3d(x)\n",
    "        # (batch, newtime, newlat, newlon, newfilter=2)\n",
    "        \n",
    "        x = tf.transpose(x, [0,4,2,3,1])\n",
    "        # (batch, 2, lat, lon, time)\n",
    "        x = self.bottleneck(x)\n",
    "        # (batch, 2, lat, lon, 1)\n",
    "        \n",
    "        x = tf.transpose(x, [0,4,2,3,1])\n",
    "        # (batch, 1, lat, lon, 2)\n",
    "        x = tf.squeeze(x,axis=1)\n",
    "        # (batch, lat, lon, 2)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvLSTM(num_filters=num_filters)\n",
    "input_shape = (batch_size, day_len, 36, 72, 2)\n",
    "# model.build(input_shape)\n",
    "# model.summary() # TODO: doesn't work cuz some layers aren't built?\n",
    "# TODO: The fact that we can't build the model probably results in undefined rank error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_weights/Version1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for whole_data in ds_future.take(1):  # just batch whole data into one batch\n",
    "    predictions = model(whole_data, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('results/pred_version1_{}'.format(scenario), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"animation.html\"] = \"jshtml\"  # allow animation for jupyter\n",
    "plt.rcParams['xtick.bottom'] = False\n",
    "plt.rcParams['xtick.labelbottom'] = False\n",
    "plt.rcParams['ytick.left'] = False\n",
    "plt.rcParams['ytick.labelleft'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []  # append each image\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "ax.set_axis_off()\n",
    "fig.add_axes(ax)\n",
    "\n",
    "for timeindex in range(total_months):  # animate for 1 yr\n",
    "    frames.append([plt.imshow(predictions[timeindex,:,:,0], # TODO: change to 1 to save NPP\n",
    "                              cmap='gray', origin='lower', animated=True)])\n",
    "\n",
    "ani = matplotlib.animation.ArtistAnimation(fig, frames, interval=100, blit=True, repeat=True)\n",
    "# ani.save('figs/pred_v1_{}_LAI.gif'.format(scenario), writer='imagemagick', fps=60)\n",
    "ani\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
